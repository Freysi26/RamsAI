# -*- coding: utf-8 -*-
"""GPT2-model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1odxz7CcJTn1IfhByGzNJB1nMaDHlhYRk

# Sækja ákveðna pakka sem eru nauðsynlegir
"""

pip install transformers torch

pip install datasets

"""# Forvinnsla gagna"""

from datasets import Dataset
import json

def load_data(file_path):
    with open(file_path, 'r') as file:
        return json.load(file)

def prepare_dataset(data):
    texts = [
        f"Recipe: {recipe['name']}\nIngredients:\n" +
        "\n".join(recipe['ingredients']) +
        "\n\n" for recipe in data
    ]
    return Dataset.from_dict({"text": texts})

recipes = load_data('recipes.json')
dataset = prepare_dataset(recipes)

"""# Þjálfun GPT-2 módels"""

from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments

tokenizer = GPT2Tokenizer.from_pretrained('gpt2')

# Set the padding token
tokenizer.pad_token = tokenizer.eos_token

# Load the model
model = GPT2LMHeadModel.from_pretrained('gpt2')

def tokenize_function(examples):
    tokens = tokenizer(examples['text'], padding='max_length', truncation=True)
    tokens['labels'] = tokens['input_ids'].copy()
    return tokens


# Tokenize the data set
tokenized_dataset = dataset.map(tokenize_function, batched=True)

# Define training arguments
training_args = TrainingArguments(
    #output_dir="./results",
    per_device_train_batch_size=2,
    num_train_epochs=1,
    logging_steps=10,
    save_strategy="epoch",
    save_total_limit=1,
    warmup_steps=10,
    prediction_loss_only=True
)

# Set up the trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset #This is our dataset
)

# Fine-tune the model
trainer.train()

"""# Búa til nýja uppskrift"""

def generate_recipe(prompt, required_ingredients, max_length=300):
    # Tokenize and encode the prompt with attention mask
    inputs = tokenizer.encode_plus(prompt, return_tensors='pt', padding=True, truncation=True).to('cuda')

    # Generate the recipe with sampling enabled
    outputs = model.generate(
        inputs['input_ids'],
        attention_mask=inputs['attention_mask'],
        max_length=max_length,
        num_return_sequences=1,
        temperature=0.8,
        do_sample=True,
        top_k=50,
        top_p=0.95,
        repetition_penalty=1.1,
        pad_token_id=tokenizer.eos_token_id
    )

    # Decode the generated text
    recipe = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Split into lines
    lines = recipe.split('\n')

    # Initialize sections
    ingredients, instructions = [], []
    current_section = None

    # Parse the results
    for line in lines:
        if "ingredients" in line.lower():
            current_section = 'ingredients'
            if not ingredients:
                ingredients.append("Ingredients:")
        elif "instructions" in line.lower():
            current_section = 'instructions'
            if not instructions:
                instructions.append("Instructions:")
        elif current_section == 'ingredients':
            if line.strip():
                ingredients.append(line)
        elif current_section == 'instructions' and line.strip():
            instructions.append(line)

    # Ensure required ingredients are explicitly mentioned with quantities
    default_quantities = {ingredient.lower(): "200g or 1 cup" for ingredient in required_ingredients}
    for ingredient in required_ingredients:
        if not any(ingredient.lower() in line.lower() for line in ingredients):
            quantity = default_quantities.get(ingredient.lower(), "as desired")
            ingredients.append(f"{ingredient.capitalize()} ({quantity})")

    # Generate additional ingredients if needed
    desired_ingredient_count = len(required_ingredients) + 2
    additional_ingredients_needed = max(0, min(6, desired_ingredient_count) - len(ingredients) + 1)

    if additional_ingredients_needed > 0:
        more_outputs = model.generate(
            inputs['input_ids'],
            attention_mask=inputs['attention_mask'],
            max_length=50,
            temperature=0.8,
            do_sample=True,
            top_k=50,
            top_p=0.95
        )
        additional_text = tokenizer.decode(more_outputs[0], skip_special_tokens=True)
        additional_lines = additional_text.split('\n')
        for line in additional_lines:
            if line.strip() and "ingredients" not in line.lower() and "instructions" not in line.lower():
                ingredients.append(line)
                if len(ingredients) >= 3 + additional_ingredients_needed:
                    break

    # Combine the sections
    formatted_recipe = "\n".join(ingredients + instructions)
    return formatted_recipe

# Gather input from the user
new_recipe_prompt = "Create a creative recipe using your selected ingredients."
user_ingredients = input("Enter the ingredients you want to use, separated by commas: ").split(',')
user_ingredients = [ingredient.strip() for ingredient in user_ingredients]

print(generate_recipe(new_recipe_prompt, user_ingredients))